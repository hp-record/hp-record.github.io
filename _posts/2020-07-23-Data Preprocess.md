---
title: 数据预处理
layout: post
categories: Data
tags: preprocess
excerpt: 数据预处理，理解标准化和归一化
---

# 目录 <span id="home">

* **[1. 引言](#1)**
* **[2. 主要内容](#2)**
* **[3. 总结](#3)**
* **[4. 参考列表](#4)**

# 1. 引言 <span id="1">  

数据中不同特征的量纲可能不一致，数值间的差别可能很大，不进行处理可能会影响到数据分析的结果，因此，需要对数据按照一定比例进行缩放，使之落在一个特定的区域，便于进行综合分析。

故，在实际情况中，拿到数据第一步就是需要做些预处理。

# 2. 主要内容<span id="2">  

* 方法

**`1.`最大-最小规范化**: 对原始数据进行线性变换，将数据映射到[0,1]区间
$$
x' = \frac{x-min(x)}{max(x)-min(x)}
$$
**`2.`Z-Score标准化**：将原始数据映射到均值为0、标准差为1的分布上
$$
x' = \frac{x-\mu}{\sigma}
$$


* 为什么要标准化/归一化？

**`1.`提升模型精度**：

标准化/归一化后，不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。

**`2.`加速模型收敛**：

标准化/归一化后，最优解的**寻优过程明显会变得平缓**，更容易正确的收敛到最优解。



* 哪些算法需要标准化和归一化

1）需要使用梯度下降和计算距离的模型要做归一化，因为不做归一化会使收敛的路径程z字型下降，导致收敛路径太慢，而且不容易找到最优解，归一化之后加快了梯度下降求最优解的速度，并有可能提高精度。比如说线性回归、逻辑回归、adaboost、xgboost、GBDT、SVM、NeuralNetwork等。需要计算距离的模型需要做归一化，比如说KNN、KMeans等。

2）概率模型、树形结构模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、随机森林。

# 3. 总结 <span id="3">  

归一化和标准化都是对数据的预处理方法，两者对比来说：归一化比标准化方法产生的标准差小，使用**归一化**来缩放数据，则数据将更集中在均值附近。这是由于归一化的缩放是“拍扁”统一到区间（仅由极值决定），而标准化的缩放是更加“弹性”和“动态”的，和整体样本的分布有很大的关系。所以归一化不能很好地处理离群值，而标准化对异常值的鲁棒性强，在许多情况下，它优于归一化。

# 4. 参考列表 <span id="4">  

[数据预处理：彻底理解标准化和归一化](https://towardsdatascience.com/data-transformation-standardisation-vs-normalisation-a47b2f38cec2)



